{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46f36f0",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b47fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilo/retrieval_rec_amazon/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Document, Prefetch, FusionQuery, Filter, FieldCondition, MatchText\n",
    "from qdrant_client import models\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "from langchain_core.messages import convert_to_openai_messages, convert_to_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "\n",
    "from utils.utils import  format_ai_message, get_tool_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de667214",
   "metadata": {},
   "source": [
    "#### Define Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97dcebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"embed_query\",\n",
    "    run_type=\"embedding\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"text-embedding-3-small\"}\n",
    ")\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    current_run = get_current_run_tree()\n",
    "\n",
    "    if current_run:\n",
    "        current_run.metadata[\"usage_metadata\"] = {\n",
    "            \"input_tokens\": response.usage.prompt_tokens,\n",
    "            \"total_tokens\": response.usage.total_tokens,\n",
    "        }\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"retrieve_data\",\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_data(query, k=5):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "    qdrant_client = QdrantClient(url=\"http://qdrant:6333\")\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"Amazon-items-collection-02-hybrid-search\",\n",
    "        prefetch = [\n",
    "            Prefetch(\n",
    "                query= query_embedding,\n",
    "                using = \"text-embedding-3-small\",\n",
    "                limit=20\n",
    "            ),\n",
    "            Prefetch(\n",
    "                query=Document(\n",
    "                    text=query,\n",
    "                    model=\"qdrant/bm25\"\n",
    "                ),\n",
    "                using = \"bm25\",\n",
    "                limit=20\n",
    "            )\n",
    "        ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=k,\n",
    "    )\n",
    "\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    similarity_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "\n",
    "    for result in results.points:\n",
    "        retrieved_context_ids.append(result.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(result.payload[\"description\"])\n",
    "        retrieved_context_ratings.append(result.payload[\"average_rating\"])\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    return {\n",
    "        \"retrieved_context_ids\": retrieved_context_ids,\n",
    "        \"retrieved_context\": retrieved_context,\n",
    "        \"retrieved_context_ratings\": retrieved_context_ratings,\n",
    "        \"similarity_scores\": similarity_scores,\n",
    "    }\n",
    "\n",
    "\n",
    "@traceable(\n",
    "    name=\"format_retrieved_context\",\n",
    "    run_type=\"prompt\"\n",
    ")\n",
    "def process_context(context):\n",
    "\n",
    "    formatted_context = \"\"\n",
    "\n",
    "    for id, chunk, rating in zip(context[\"retrieved_context_ids\"], context[\"retrieved_context\"], context[\"retrieved_context_ratings\"]):\n",
    "        formatted_context += f\"- ID: {id}, rating: {rating}, description: {chunk}\\n\"\n",
    "\n",
    "    return formatted_context\n",
    "\n",
    "def get_formatted_context(query:str, top_k: int = 5)-> str:\n",
    "    \"\"\"Get the top k contexts, each representing an inventory item for a given query.\n",
    "    \n",
    "    Args:\n",
    "        query: The query to get the top k contexts from\n",
    "        top_k: The number of context chunks to retrieve, works best with 5 or more\n",
    "        \n",
    "    Returns:\n",
    "        A string of the top k context chunks with IDs and average ratings prepending each chunk, each representing an inventory item for a given query.\"\"\"\n",
    "\n",
    "    context = retrieve_data(query, top_k)\n",
    "    formatted_context = process_context(context)\n",
    "\n",
    "    return formatted_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4e7bd",
   "metadata": {},
   "source": [
    "#### State and Pydantic Models for Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a82c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description =\" The ID of the item used to answer the question\")\n",
    "    description: str = Field(description =\" Short description of the item used to answer the question\")\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[str], add] = []\n",
    "    question_relevant: bool = False\n",
    "    iteration: int = 0\n",
    "    answer: str = \"\"\n",
    "    available_tools : List[Dict[str, Any]] = []\n",
    "    tool_calls: List[ToolCall] = []\n",
    "    final_answer: bool = False\n",
    "    references : Annotated[List[RAGUsedContext], add] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32babb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@traceable(\n",
    "    name = \"agent_node\",\n",
    "    run_type = \"llm\",\n",
    "    metadata = {\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def agent_node(state:State) -> dict:\n",
    "    prompt_template = \"\"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a conversation history and a list of tools you can use to answer the latest query.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "When making tool calls, use this exact format:\n",
    "{\n",
    "    \"name\": \"tool_name\",\n",
    "    \"arguments\": {\n",
    "        \"parameter1\": \"value1\",\n",
    "        \"parameter2\": \"value2\",\n",
    "    }\n",
    "}\n",
    "\n",
    "CRITICAL: All parameters must go inside the \"arguments\" object, not at the top level of the tool call.\n",
    "\n",
    "Examples:\n",
    "- Get formatted item context:\n",
    "{\n",
    "    \"name\": \"get_formatted_item_context\",\n",
    "    \"arguments\": {\n",
    "        \"query\": \"Kool kids toys.\",\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If tool_calls has values, final_answer MUST be false\n",
    "(You cannot call tools and exit the graph in the same response)\n",
    "- If final_answer is true, tool_calls MUST be []\n",
    "(You must wait for tool results before exiting the graph)\n",
    "- If you need tool results before answering, set:\n",
    "tool_calls=[...], final_answer=false\n",
    "- After receiving tool results, you can then set:\n",
    "tool_calls=[], final_answer=true\n",
    "- Use names specificly provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the outputs from the tools using the available tools only.\n",
    "- Do not suggest the same tool call more than once.\n",
    "- If the question can be decomposed into multiple sub-questions, suggest all of them.\n",
    "- If multipple tool calls can be used at once to answer the question, suggest all of them.\n",
    "- Do not explain your next steps in the answer, instead use tools to answer the question.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As an output you need to return the following:\n",
    "\n",
    "* answer: The answer to the question based on your current knowledge and the tool results.\n",
    "* references: The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Each reference should have an id and a short description of the item based on the retrieved context.\n",
    "* final_answer: True if you have all the information needed to provide a complete answer, False otherwise.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and should be returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function names and arguments.\n",
    "\"\"\"\n",
    "    \n",
    "    template = Template(prompt_template)\n",
    "\n",
    "    prompt = template.render(\n",
    "        available_tools = state.available_tools\n",
    "    )\n",
    "    messages = state.messages\n",
    "    conversation = convert_to_openai_messages(messages)\n",
    "\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model =\"gpt-4.1-mini\",\n",
    "        response_model = AgentResponse,\n",
    "        messages= [{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature =0.5,\n",
    "    )\n",
    "\n",
    "    ai_message = format_ai_message(response)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [ai_message],\n",
    "        \"tool_calls\": response.tool_calls,\n",
    "        \"iteration\": state.iteration +1,\n",
    "        \"answer\": response.answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd66fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b4d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1686359",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
